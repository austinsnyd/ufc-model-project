---
title: "UFC_log_reg"
author: "Austin Snyder"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(car)
library(caret)
library(ROCR)
library(MASS)
library(dplyr)
```

## Prep Data

```{r}
ufc_men_imp <- readRDS("ufc_men_imp.rds")
ufc_logreg_data <- ufc_men_imp %>% select(-RedFighter, -BlueFighter, -Date, -Location, -Country)
```

```{r}
str(ufc_logreg_data)  # Check data types
colSums(is.na(ufc_logreg_data))  # Check for missing values
```

### Alias 
I need to remove highly correlated values for logistic regression. 
```{r}

# Fit the model to check for aliased coefficients
alias_check <- alias(lm(as.numeric(Winner) ~ ., data = ufc_logreg_data))
print(alias_check)

```

### VIF
I use VIF to check for multicollinearity.
```{r}
# Identify numeric features (exclude Winner from selection)
numeric_features <- names(ufc_logreg_data)[sapply(ufc_logreg_data, is.numeric)]

# Ensure Winner is included in the dataset for lm() formula
logreg_numeric <- ufc_logreg_data %>% select(all_of(numeric_features), Winner)

# Compute VIF (use the full dataset with Winner)
vif_model <- lm(as.numeric(Winner) ~ ., data = logreg_numeric)

# Extract VIF values
vif_values <- vif(vif_model)
vif_values[vif_values > 5]
```


### Split Data into Training and Testing Sets

```{r}
# Set seed for reproducibility
set.seed(1616)

# Split data (80% train, 20% test)
train_index <- createDataPartition(ufc_logreg_data$Winner, p = 0.8, list = FALSE)
train_data <- ufc_logreg_data[train_index, ]
test_data <- ufc_logreg_data[-train_index, ]

# Confirm split sizes
dim(train_data)  # Should be ~80% of total rows
dim(test_data)   # Should be ~20% of total rows
```

```{r}
table(train_data$Winner) / nrow(train_data)  # Class proportions in training set
table(test_data$Winner) / nrow(test_data)    # Class proportions in test set

```
### Standardize Data
```{r}
# Ensure numeric features are correctly selected
numeric_features <- names(train_data)[sapply(train_data, is.numeric)]

# Compute means and standard deviations from training set
train_means <- colMeans(train_data[numeric_features])
train_sds <- apply(train_data[numeric_features], 2, sd)

# Avoid division by zero
train_sds[train_sds == 0] <- 1  

# Standardize test data using TRAINING means & SDs
test_data[numeric_features] <- scale(test_data[numeric_features], 
                                     center = train_means, 
                                     scale = train_sds)

```


```{r}
# Check means (should be close to 0)
apply(test_data[numeric_features], 2, mean)

# Check standard deviations (should be close to 1)
apply(test_data[numeric_features], 2, sd)

```


## Modeling

### Fit Logistic Regression Model

```{r}
logit_model <- glm(Winner ~ ., data = train_data, family = binomial)
summary(logit_model)  # Check coefficients and significance
```

Null Deviance: 6230.0 → Deviance of a model with only an intercept.
Residual Deviance: 5548.8 → Deviance after adding predictors.
AIC (Akaike Information Criterion): 5694.8 → Lower values indicate a better fit.


## Simplify model 
```{r}
logit_rev1 <- glm(Winner ~ BlueCurrentWinStreak + BlueDraws + 
                             RedAvgSigStrPct + RedWinsByDecisionSplit + 
                             RedAge + BlueAge + TotalFightTimeSecs + 
                             BlueDecOdds + BSubOdds + BKOOdds + 
                             Log_EVRatio + Finish + FinishRound, 
                             data = train_data, family = binomial)

summary(logit_rev1)


```
Null Deviance: 6230.0 (when no predictors are used)
Residual Deviance: 5603.3 (with predictors)
AIC (Akaike Information Criterion): 5641.3

## Evaluate 

```{r}
test_data$Predicted <- predict(logit_rev1, newdata = test_data, type = "response")
test_data$PredictedClass <- factor(ifelse(test_data$Predicted > 0.01, "Red", "Blue"), 
                                   levels = levels(test_data$Winner))
table(test_data$PredictedClass, test_data$Winner)  # Confusion Matrix

```

```{r}
# Compute accuracy
accuracy <- sum(test_data$PredictedClass == test_data$Winner) / nrow(test_data)
print(paste("Accuracy:", round(accuracy * 100, 2), "%"))

```

```{r}
conf_matrix <- table(test_data$PredictedClass, test_data$Winner)

# Compute precision, recall, and F1-score
precision <- conf_matrix["Red", "Red"] / sum(conf_matrix["Red", ])  # True Positives / (True Positives + False Positives)
recall <- conf_matrix["Red", "Red"] / sum(conf_matrix[, "Red"])  # True Positives / (True Positives + False Negatives)
f1_score <- 2 * (precision * recall) / (precision + recall)

print(paste("Precision:", round(precision, 2)))
print(paste("Recall:", round(recall, 2)))
print(paste("F1 Score:", round(f1_score, 2)))
```



```{r}


# Define upsampling method
train_control <- trainControl(method = "repeatedcv", number = 10, repeats = 3, sampling = "up")

# Train logistic regression with upsampling
logit_balanced <- train(Winner ~ ., data = train_data, method = "glm", 
                        family = binomial, trControl = train_control)

summary(logit_balanced)

```


```{r}
set.seed(1616)
red_fights <- train_data[train_data$Winner == "Red", ]
blue_fights <- train_data[train_data$Winner == "Blue", ]

# Downsample "Red" to match "Blue"
red_fights_downsampled <- red_fights[sample(nrow(red_fights), nrow(blue_fights)), ]
train_data_balanced <- rbind(red_fights_downsampled, blue_fights)

# Shuffle dataset
set.seed(1616)
train_data_balanced <- train_data_balanced[sample(nrow(train_data_balanced)), ]

# Train model on balanced dataset
logit_balanced <- glm(Winner ~ ., data = train_data_balanced, family = binomial)
summary(logit_balanced)

```

```{r}
test_data$Predicted <- predict(logit_balanced, newdata = test_data, type = "response")
test_data$PredictedClass <- factor(ifelse(test_data$Predicted > 0.005, "Red", "Blue"), 
                                   levels = levels(test_data$Winner))

```

```{r}
conf_matrix <- table(test_data$PredictedClass, test_data$Winner)
print(conf_matrix)

# Compute accuracy
accuracy <- sum(test_data$PredictedClass == test_data$Winner) / nrow(test_data)
print(paste("Updated Accuracy:", round(accuracy * 100, 2), "%"))

```
```{r}
pred <- prediction(test_data$Predicted, test_data$Winner)
perf <- performance(pred, "tpr", "fpr")

# Compute AUC
auc <- performance(pred, "auc")@y.values[[1]]
print(paste("AUC:", round(auc, 4)))

# Plot ROC Curve
plot(perf, col="blue", lwd=2, main="ROC Curve - Logistic Regression")
abline(a=0, b=1, lty=2, col="gray")
```



```{r}

logit_final <- glm(Winner ~ BlueCurrentWinStreak + BlueDraws + RedAvgSigStrPct + 
                             RedAvgTDPct + RedWinsByDecisionSplit + RedWinsByDecisionUnanimous + 
                             RedStance + RedAge + BlueAge + ReachDif + Finish + FinishRound + 
                             TotalFightTimeSecs + BlueDecOdds + BSubOdds + BKOOdds + Log_EVRatio, 
                             family = binomial, data = train_data_balanced)

summary(logit_final)

```

```{r}
test_data$Predicted <- predict(logit_final, newdata = test_data, type = "response")
test_data$PredictedClass <- factor(ifelse(test_data$Predicted > 0.078, "Red", "Blue"), 
                                   levels = levels(test_data$Winner))

```

```{r}
conf_matrix <- table(test_data$PredictedClass, test_data$Winner)
print(conf_matrix)

# Compute accuracy
accuracy <- sum(test_data$PredictedClass == test_data$Winner) / nrow(test_data)
print(paste("Final Model Accuracy:", round(accuracy * 100, 2), "%"))

```
```{r}
precision <- conf_matrix["Red", "Red"] / sum(conf_matrix["Red", ])  
recall <- conf_matrix["Red", "Red"] / sum(conf_matrix[, "Red"])  
f1_score <- 2 * (precision * recall) / (precision + recall)

print(paste("Precision:", round(precision, 2)))
print(paste("Recall:", round(recall, 2)))
print(paste("F1 Score:", round(f1_score, 2)))

```

```{r}
pred <- prediction(test_data$Predicted, test_data$Winner)
perf <- performance(pred, "tpr", "fpr")

# Compute AUC
auc <- performance(pred, "auc")@y.values[[1]]
print(paste("AUC:", round(auc, 4)))

# Plot ROC Curve
plot(perf, col="blue", lwd=2, main="ROC Curve - Final Logistic Regression Model")
abline(a=0, b=1, lty=2, col="gray")

```

