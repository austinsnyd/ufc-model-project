---
title: "UFC_boost"
author: "Austin Snyder"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(xgboost)
library(Matrix)
library(caret)
library(dplyr)
```


## Data
```{r}
## load data
ufc_men_imp <- readRDS("ufc_men_imp.rds")
ufc_boost_data <- ufc_men_imp
```

```{r}
## inspect structure 
str(ufc_boost_data)
```


```{r}
## remove non-numeric columns
ufc_boost_data <- ufc_men_imp %>%
  select(-c(RedFighter, BlueFighter, Date, Location, Country))

```



```{r}
## convert factors to numeric
 ufc_boost_data <- ufc_boost_data %>%
  mutate(across(where(is.factor), as.numeric))

## convert "Red" & "Blue" to 0/1
ufc_boost_data$Winner <- as.numeric(ufc_boost_data$Winner) - 1  # Convert "Red" & "Blue" to 0/1

```


```{r}
## check for NA's
sum(is.na(ufc_boost_data))
```

### Split Data
```{r}
set.seed(1818)  # Ensure reproducibility

# Create partition
trainIndex <- createDataPartition(ufc_boost_data$Winner, p = 0.8, list = FALSE)

# Split into training and testing sets
train_data <- ufc_boost_data[trainIndex, ]
test_data <- ufc_boost_data[-trainIndex, ]

# Separate features and target
train_features <- train_data %>% select(-Winner)
train_target <- train_data$Winner

test_features <- test_data %>% select(-Winner)
test_target <- test_data$Winner

```

### Matrix format 

```{r}
dtrain <- xgb.DMatrix(data = as.matrix(train_features), label = train_target)
dtest <- xgb.DMatrix(data = as.matrix(test_features), label = test_target)

```


## Train
```{r}
params <- list(
  objective = "binary:logistic",  # Binary classification
  eval_metric = "logloss",        # Log loss for classification
  max_depth = 6,                  # Controls tree complexity
  eta = 0.3,                      # Learning rate
  subsample = 0.8,                # Subsampling of data
  colsample_bytree = 0.8          # Subsampling of features
)

# Train model with early stopping
xgb_model <- xgb.train(
  params = params,
  data = dtrain,
  nrounds = 100,                 # Number of boosting rounds
  watchlist = list(train = dtrain, test = dtest),
  early_stopping_rounds = 10,     # Stop if no improvement
  verbose = 1
)

```

## predict 
```{r}
# Predict probabilities
pred_probs <- predict(xgb_model, dtest)

# Convert to binary labels
pred_labels <- ifelse(pred_probs > 0.5, 1, 0)

```

## Evaluate
```{r}
# Confusion Matrix
conf_matrix <- table(Predicted = pred_labels, Actual = test_target)
print(conf_matrix)

# Accuracy
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
print(paste("Accuracy:", round(accuracy, 4)))

```

## Feature Importance 
```{r}
# Get importance
importance_matrix <- xgb.importance(feature_names = colnames(train_features), model = xgb_model)

# Plot feature importance
xgb.plot.importance(importance_matrix)

```


### attempt with top 20 features 
```{r}
# Extract the top 20 most important features dynamically
top_features <- importance_matrix$Feature[1:20]  # Get top 20 features based on importance
top_features <- c(top_features, "Winner")  # Ensure "Winner" target variable is included

# Select only the top features from the dataset
ufc_boost_data_top <- ufc_boost_data %>% select(all_of(top_features))

# Split Data Again
set.seed(1818)

trainIndex <- createDataPartition(ufc_boost_data_top$Winner, p = 0.8, list = FALSE)

train_data <- ufc_boost_data_top[trainIndex, ]
test_data <- ufc_boost_data_top[-trainIndex, ]

# Separate Features and Target Variable
train_features <- train_data %>% select(-Winner)
train_target <- train_data$Winner

test_features <- test_data %>% select(-Winner)
test_target <- test_data$Winner


```

## increase rounds 
```{r}
xgb_final <- xgb.train(
  params = list(
    objective = "binary:logistic",
    eval_metric = "logloss",
    max_depth = 6,
    eta = 0.1,  # Lower learning rate for better generalization
    gamma = 1,
    colsample_bytree = 0.8,
    min_child_weight = 1,
    subsample = 0.8
  ),
  data = xgb.DMatrix(data = as.matrix(train_features), label = train_target),
  nrounds = 400,  # Increase number of boosting rounds
  watchlist = list(train = xgb.DMatrix(data = as.matrix(train_features), label = train_target), 
                   test = xgb.DMatrix(data = as.matrix(test_features), label = test_target)),
  early_stopping_rounds = 20,
  verbose = 1
)

```

## balance weight classes 
```{r}
# Compute class weights
weight_pos <- sum(train_target == 0) / sum(train_target == 1)

xgb_final <- xgb.train(
  params = list(
    objective = "binary:logistic",
    eval_metric = "logloss",
    max_depth = 6,
    eta = 0.1,
    gamma = 1,
    colsample_bytree = 0.8,
    min_child_weight = 1,
    subsample = 0.8,
    scale_pos_weight = weight_pos  # Adjust weight balance
  ),
  data = xgb.DMatrix(data = as.matrix(train_features), label = train_target),
  nrounds = 400,
  watchlist = list(train = xgb.DMatrix(data = as.matrix(train_features), label = train_target), 
                   test = xgb.DMatrix(data = as.matrix(test_features), label = test_target)),
  early_stopping_rounds = 20,
  verbose = 1
)

```

## reevaluate 
```{r}

params <- list(
  objective = "binary:logistic",
  eval_metric = "logloss",
  max_depth = 8,
  eta = 0.12,  # Small boost for better refinement
  gamma = 1.5,  # Less strict regularization
  colsample_bytree = 0.9,
  min_child_weight = 2, 
  subsample = 0.85,
  scale_pos_weight = 0.60
)

xgb_final <- xgb.train(
  params = params,
  data = xgb.DMatrix(data = as.matrix(train_features), label = train_target),
  nrounds = 700,  # More rounds to refine learning
  watchlist = list(train = xgb.DMatrix(data = as.matrix(train_features), label = train_target), 
                   test = xgb.DMatrix(data = as.matrix(test_features), label = test_target)),
  early_stopping_rounds = 20,
  verbose = 1
)

# Make Predictions
pred_probs <- predict(xgb_final, xgb.DMatrix(data = as.matrix(test_features)))

# Try different probability thresholds
thresholds <- seq(0.415, 0.465, by = 0.005)  
best_acc <- 0
best_threshold <- 0.5

for (t in thresholds) {
  pred_labels <- ifelse(pred_probs > t, 1, 0)
  conf_matrix <- table(Predicted = pred_labels, Actual = test_target)
  acc <- sum(diag(conf_matrix)) / sum(conf_matrix)
  
  if (acc > best_acc) {
    best_acc <- acc
    best_threshold <- t
  }
}

print(paste("Best threshold:", best_threshold, "with accuracy:", round(best_acc, 4)))

# Apply the best threshold
final_pred_labels <- ifelse(pred_probs > best_threshold, 1, 0)

# Final Confusion Matrix
final_conf_matrix <- table(Predicted = final_pred_labels, Actual = test_target)
print(final_conf_matrix)

# Final Accuracy
final_accuracy <- sum(diag(final_conf_matrix)) / sum(final_conf_matrix)
print(paste("Final Accuracy:", round(final_accuracy, 4)))


```




```{r}
# Convert test data to DMatrix format
dtest <- xgb.DMatrix(data = as.matrix(test_features))

# Generate probability predictions for XGBoost
xgb_pred_probs <- predict(xgb_final, dtest)

```

```{r}
# Compute ROC curve
xgb_roc_obj <- roc(test_target, xgb_pred_probs)

# Print AUC value
xgb_auc <- auc(xgb_roc_obj)
print(paste("XGBoost AUC:", round(xgb_auc, 4)))

```


